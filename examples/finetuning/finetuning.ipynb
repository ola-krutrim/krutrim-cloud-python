{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Fine-Tuning Models on Krutrim Cloud\n",
            "This notebook demonstrates how to fine-tune models on Krutrim Cloud using various engines and modes, manage datasets, create fine-tuning tasks, and monitor their status. It provides step-by-step instructions to perform tasks such as listing supported models, creating and retrieving datasets, initiating fine-tuning tasks, and managing them effectively."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Install Krutrim Cloud SDK"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "%pip install krutrim-cloud"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Prerequisite\n",
            "**Export the Required Environment Variables:** Create a .env file in the examples directory with the following details:\n",
            "\n",
            "- KRUTRIM_CLOUD_API_KEY=\"Your Krutrim Cloud API Key\"\n",
            "\n",
            "- KRUTRIM_CLOUD_S3_REGION = \"Your Krurim Cloud S3 Region\"\n",
            "\n",
            "- KRUTRIM_CLOUD_S3_PUBLIC_KEY = \"Your Krutrim Cloud S3 Public Key\"\n",
            "\n",
            "- KRUTRIM_CLOUD_S3_BUCKET_ENDPOINT = \"Your Krutrim Cloud Bucket Endpoint URL\"\n",
            "\n",
            "- KRUTRIM_CLOUD_S3_SECRET_KEY = \"Your Krutrim Cloud S3 Access Key\"\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Import Libraries and Load Environment Variables\n",
            "- **Purpose**: To prepare the environment for the script.\n",
            "- **Key Actions**:\n",
            "    -  Import necessary libraries (krutrim_cloud for API access, dotenv for environment variables).\n",
            "    - Load environment variables from a .env file."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Import necessary libraries\n",
            "from krutrim_cloud import KrutrimCloud\n",
            "from dotenv import load_dotenv\n",
            "import os\n",
            "# Load environment variables from .env file\n",
            "load_dotenv()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Initialize KrutrimCloud Client\n",
            "- **Purpose:** To set up the API client for making requests.\n",
            "- **Key Actions:**\n",
            "    - Create an instance of KrutrimCloud using the base URL from environment variables."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Initialize KrutrimCloud client\n",
            "client = KrutrimCloud()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Supported Models\n",
            "- **Purpose:** To see which models are available for fine-tuning.\n",
            "- **Key Actions:**\n",
            "    - Retrieve and print a list of all supported models."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['Meta-Llama-3-8B', 'Meta-Llama-3-8B-instruct', 'Mistral-7B']\n"
               ]
            }
         ],
         "source": [
            "# List all the supported models\n",
            "try:\n",
            "    supported_model_list = client.fine_tuning.models.list()\n",
            "    print(supported_model_list)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while listing supported models: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Fine-Tuning Engines\n",
            "- **Purpose:** To identify the frameworks available for fine-tuning.\n",
            "- **Key Actions**:\n",
            "    - Fetch and display names of all fine-tuning engines."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['torchtune', 'nemo']\n"
               ]
            }
         ],
         "source": [
            "# List fine_tuning engine(framework) name\n",
            "try:\n",
            "    fine_tuning_engines = client.fine_tuning.engines.list()\n",
            "    print(fine_tuning_engines)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while listing fine-tuning engines: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Models Supported by a Specific Engine\n",
            "- **Purpose:** To find models compatible with a specific fine-tuning engine.\n",
            "- **Key Actions:**\n",
            "    - Retrieve models supported by the engine and print them."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['Meta-Llama-3-8B', 'Meta-Llama-3-8B-instruct', 'Mistral-7B']\n"
               ]
            }
         ],
         "source": [
            "# List all models supported by the given engine\n",
            "try:\n",
            "    engine = fine_tuning_engines[0]\n",
            "    supported_models = client.fine_tuning.models.retrieve(engine)\n",
            "    print(supported_models)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving models for the given engine: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Supported Fine-Tuning Modes\n",
            "- **Purpose:** To understand the available training configurations.\n",
            "- **Key Actions:**\n",
            "    - List all fine-tuning modes supported by the API."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['full', 'lora', 'lora_dpo']\n"
               ]
            }
         ],
         "source": [
            "# List all supported fine_tuning modes\n",
            "try:\n",
            "    supported_modes = client.fine_tuning.modes.list()\n",
            "    print(supported_modes)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while listing supported fine-tuning modes: {e}\")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Models by Engine and Mode\n",
            "- **Purpose:** To narrow down models based on engine and mode.\n",
            "- **Key Actions:**\n",
            "    - Retrieve models that work with the specified engine and mode."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['Meta-Llama-3-8B', 'Meta-Llama-3-8B-instruct', 'Mistral-7B']\n"
               ]
            }
         ],
         "source": [
            "# List all models supported by the given engine and mode\n",
            "try:\n",
            "    engine = fine_tuning_engines[0]\n",
            "    mode = supported_modes[0]\n",
            "    supported_models_given_engine_mode = client.fine_tuning.models.mode.retrieve(engine=engine, mode=mode)\n",
            "    print(supported_models_given_engine_mode)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving models for the given engine and mode: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Modes Supported by a Given Engine\n",
            "- **Purpose:** To check modes available for a specific engine.\n",
            "- **Key Actions:**\n",
            "    - Display modes supported by the engine."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['full', 'lora', 'lora_dpo']\n"
               ]
            }
         ],
         "source": [
            "# List all modes supported by the given engine\n",
            "try:\n",
            "    engine = fine_tuning_engines[0]\n",
            "    supported_modes_given_engine = client.fine_tuning.modes.retrieve(engine=engine)\n",
            "    print(supported_modes_given_engine)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving modes for the given engine: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Modes Supported by a Given Engine and Model\n",
            "- **Purpose:** To determine modes available for a specific engine and model.\n",
            "- **Key Actions:**\n",
            "    - Retrieve modes for the engine and model."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['full', 'lora', 'lora_dpo']\n"
               ]
            }
         ],
         "source": [
            "# List all modes supported by the given engine and model\n",
            "try:\n",
            "    engine = fine_tuning_engines[0]\n",
            "    model = supported_model_list[0]\n",
            "    supported_modes_given_engine_model = client.fine_tuning.modes.model.retrieve(engine=engine, model=model)\n",
            "    print(supported_modes_given_engine_model)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving modes for the given engine and model: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Fine-Tuning Engine by Model\n",
            "- **Purpose:** To find the engine used for a specific model.\n",
            "- **Key Actions:**\n",
            "    - Display the fine-tuning engine for the model."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['torchtune', 'nemo']\n"
               ]
            }
         ],
         "source": [
            "# List fine_tuning engine(framework) by the given model\n",
            "try:\n",
            "    model = supported_model_list[0]\n",
            "    finetune_engine_given_model = client.fine_tuning.engines.model.retrieve(model=model)\n",
            "    print(finetune_engine_given_model)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving fine-tuning engine for the given model: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List Fine-Tuning Engine by Model and Mode\n",
            "- **Purpose:** To see which engine can be used with a model in a specific mode.\n",
            "- **Key Actions:**\n",
            "    - Retrieve the engine for given model and mode."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['torchtune']\n"
               ]
            }
         ],
         "source": [
            "# List fine_tuning engine(framework) by the given model and mode\n",
            "try:\n",
            "    model = supported_model_list[0]\n",
            "    mode = supported_modes[0]\n",
            "    finetune_engine_given_model = client.fine_tuning.engines.model.mode.retrieve(model=model, mode=mode)\n",
            "    print(finetune_engine_given_model)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving fine-tuning engine for the given model and mode: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Create Datasets using File Object\n",
            "- **Purpose:** To upload datasets for fine-tuning tasks.\n",
            "- **Key Actions:**\n",
            "    - Open and upload a dataset file, using the path from environment variables."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Create Datasets\n",
            "try:\n",
            "    dataset_path = \"/Users/harsha.s1/Downloads/ft-alpaca-tiny.json\"\n",
            "    with open(dataset_path, 'rb') as file:\n",
            "        create_dataset = client.fine_tuning.datasets.create(file=file)\n",
            "except FileNotFoundError:\n",
            "    print(f\"Dataset file not found at path: {dataset_path}\")\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while creating the dataset: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Create Datasets using S3\n",
            "- **Purpose:**\n",
            "    - Upload a local file from your system to an S3 bucket using the SDK's method.\n",
            "    - Copy a dataset from a user's own S3 bucket to the fine-tuning service\n",
            "- **Key Actions:**\n",
            "    - Uploads a local file to the specified S3 bucket using the SDK and handles potential errors gracefully.\n",
            "    - Use the SDKâ€™s copy method to transfer the dataset file and handle any exceptions that occur."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "try:\n",
            "    local_directory = \"/Users/harsha.s1/Downloads/ft-alpaca-tiny_sample3.json\"\n",
            "    bucket_name = \"dvc-model-catalogue\"\n",
            "    s3_data = client.fine_tuning.upload_files_to_s3(\n",
            "            local_dir_path=local_directory,\n",
            "            bucket_name=bucket_name\n",
            "        )\n",
            "\n",
            "    dataset_info = client.fine_tuning.datasets.copy(filename=s3_data[\"filename\"],\n",
            "                                       path=s3_data[\"s3-path\"],\n",
            "                                       s3_region=os.getenv(\"KRUTRIM_CLOUD_S3_REGION\"),\n",
            "                                       s3_access_key=os.getenv(\"KRUTRIM_CLOUD_S3_PUBLIC_KEY\"),\n",
            "                                       s3_endpoint=os.getenv(\"KRUTRIM_CLOUD_S3_BUCKET_ENDPOINT\"),\n",
            "                                       s3_secret=os.getenv(\"KRUTRIM_CLOUD_S3_SECRET_KEY\")\n",
            "                                      )\n",
            "    print(f\"Dataset successfully copied: {dataset_info.name}\")\n",
            "except Exception as exc:\n",
            "    print(f\"Exception while uploading data: {exc}\")\n",
            "    "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List All Datasets\n",
            "- **Purpose:** To view datasets that have been uploaded.\n",
            "- **Key Actions:**\n",
            "    - Retrieve and print all available datasets."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Datasets: 0\n",
                  "name=databricks-dolly-15k.json\n",
                  "Datasets: 1\n",
                  "name=ft-alpaca-tiny.json\n",
                  "Datasets: 2\n",
                  "name=ft-alpaca-tiny_sample.json\n",
                  "Datasets: 3\n",
                  "name=ft-alpaca-tiny_sample1.json\n",
                  "Datasets: 4\n",
                  "name=law-qa-test.json\n"
               ]
            }
         ],
         "source": [
            "# List all datasets\n",
            "try:\n",
            "    dataset_list = client.fine_tuning.datasets.list()\n",
            "    if dataset_list:\n",
            "        for index, dataset in enumerate(dataset_list):\n",
            "            print(f\"Datasets: {index}\")\n",
            "            print(f\"name={dataset.name}\")\n",
            "    else:\n",
            "        print(\"No datasets found.\")\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while listing datasets: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Read a Specific Dataset\n",
            "- **Purpose:** To verify the contents of a dataset.\n",
            "- **Key Actions:**\n",
            "    - Retrieve and display the contents of a specific dataset file."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['{\"instruction\": \"When did Virgin Australia start operating?\", \"context\": \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia\\'s domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly se...']\n"
               ]
            }
         ],
         "source": [
            "# Read the datasets\n",
            "try:\n",
            "    filename = dataset_list[0].name\n",
            "    data = client.fine_tuning.datasets.retrieve(filename=filename)\n",
            "    print(data)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving the dataset: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Delete a Specific Dataset\n",
            "- **Purpose:** To manage datasets by removing unnecessary ones.\n",
            "- **Key Actions:**\n",
            "   - Delete a specific dataset using its filename."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Delete the Dataset\n",
            "try:\n",
            "    delete_response = client.fine_tuning.datasets.delete(filename=dataset_list[0].name)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while deleting the dataset: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Create a Fine-Tuning Task\n",
            "- **Purpose:** To define and initiate a new fine-tuning task.\n",
            "- Key Actions:\n",
            "    - Set parameters (engine, model, dataset, etc.) and create the fine-tuning task."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "TaskCreateResponse(task_id='49bd242d-5f3d-4e47-8640-2a5e7a5454fe')\n"
               ]
            }
         ],
         "source": [
            "# Create finetuning task\n",
            "try:\n",
            "    create_finetuning_task = client.fine_tuning.tasks.create(\n",
            "        engine=\"torchtune\",\n",
            "        task_name=\"ft_task_1\",\n",
            "        namespace=\"gpu-scheduler\",\n",
            "        priority=0,\n",
            "        model=\"Meta-Llama-3-8B-instruct\",\n",
            "        mode=\"lora\",\n",
            "        dataset=\"ft-alpaca-tiny.json\",\n",
            "        test_dataset=\"\",\n",
            "        ngpu=1,\n",
            "        lora_rank=0,\n",
            "        lora_alpha=0,\n",
            "        batch=4,\n",
            "        lr=1,\n",
            "        epoch=1,\n",
            "        seed=0,\n",
            "        version=\"v1\",\n",
            "        total_checkpoint=1\n",
            "    )\n",
            "    print(create_finetuning_task)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while creating the fine-tuning task: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## List All Fine-Tuning Tasks\n",
            "- **Purpose:** To track ongoing and completed fine-tuning tasks.\n",
            "- **Key Actions:**\n",
            "    - Retrieve and display all fine-tuning tasks."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Fine-tuning Task: 0\n",
                  "name=ft_task_1\n",
                  "model=Meta-Llama-3-8B-instruct\n",
                  "id=49bd242d-5f3d-4e47-8640-2a5e7a5454fe\n",
                  "status=starting\n",
                  "mtime=09/27/2024 04_32_38 UTC\n",
                  "total_checkpoint=1\n",
                  "checkpoints=[{'name': 'ft-9ea84101-4cee-4b80-8b31-5e67d8628b98-ft_task_1_1_final', 'status': 'succeed'}]\n"
               ]
            }
         ],
         "source": [
            "# List fine_tuning Tasks\n",
            "try:\n",
            "    finetuning_tasks_list = client.fine_tuning.tasks.list()\n",
            "    if finetuning_tasks_list.task_list:\n",
            "        for index, task in enumerate(finetuning_tasks_list.task_list):\n",
            "            print(f\"\\nFine-tuning Task: {index}\")\n",
            "            for key, value in task.items():\n",
            "                print(f\"{key}={value}\")\n",
            "    else:\n",
            "        print(\"No fine-tuning tasks found.\")\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while listing fine-tuning tasks: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Retrieve a Specific Fine-Tuning Task\n",
            "- **Purpose:** To inspect details of a particular fine-tuning task.\n",
            "- **Key Actions:**\n",
            "   - Retrieve task information using its unique ID."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "id=49bd242d-5f3d-4e47-8640-2a5e7a5454fe\n",
                  "batch=4\n",
                  "checkpoints=[{'name': 'ft-9ea84101-4cee-4b80-8b31-5e67d8628b98-ft_task_1_1_final', 'status': 'succeed'}]\n",
                  "ctime=09/27/2024 04_32_29 UTC\n",
                  "dataset=ft-alpaca-tiny.json\n",
                  "dataset_size=18478\n",
                  "epoch=1\n",
                  "lora_alpha=0\n",
                  "lora_rank=0\n",
                  "lr=1\n",
                  "mode=lora\n",
                  "model=Meta-Llama-3-8B-instruct\n",
                  "name=ft_task_1\n",
                  "namespace=gpu-scheduler\n",
                  "ngpu=1\n",
                  "priority=0\n",
                  "reason=out_of_gpu\n",
                  "seed=0\n",
                  "status=starting\n",
                  "test_dataset=\n",
                  "test_dataset_size=0\n",
                  "total_checkpoint=1\n",
                  "version=v1\n"
               ]
            }
         ],
         "source": [
            "# Get fine_tuning task\n",
            "try:\n",
            "    id = finetuning_tasks_list.task_list[0].get(\"id\")\n",
            "    finetuning_task = client.fine_tuning.tasks.retrieve(id=id)\n",
            "    for key, value in finetuning_task.__dict__.items():\n",
            "        print(f\"{key}={value}\")\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving the fine-tuning task: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Retrieve Logs for a Specific Fine-Tuning Task\n",
            "- **Purpose:** To monitor training progress through logs.\n",
            "- **Key Actions:**\n",
            "    - Fetch logs for a specified fine-tuning task."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Get all logs from the finetuning_task\n",
            "try:\n",
            "    id = finetuning_tasks_list.task_list[0].get(\"id\")\n",
            "    finetuning_logs = client.fine_tuning.tasks.logs(id=id)\n",
            "    for log_item in finetuning_logs:\n",
            "        print(\"\\nLog Entry:\")\n",
            "        for key, value in log_item.__dict__.items():\n",
            "            print(f\"{key}={value}\")\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while retrieving logs for the fine-tuning task: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Cancel a Specific Fine-Tuning Task\n",
            "- **Purpose:** To stop an ongoing fine-tuning task if needed.\n",
            "- **Key Actions:**\n",
            "    - Cancel a task using its unique ID.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Cancel fine_tuning task\n",
            "try:\n",
            "    id = finetuning_tasks_list.task_list[0].get(\"id\")\n",
            "    cancel_response = client.fine_tuning.tasks.cancel(id=id)\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while cancelling the fine-tuning task: {e}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}